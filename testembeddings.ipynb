{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with Embeddings\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset (16,)\n",
      "embeddings (100, 8)\n",
      "embed (16, 8)\n",
      "[83  4 10 82 28 19 79 90 48 97 13 12  5 34 26 13]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "batch_size = 16\n",
    "embedding_size = 8\n",
    "vocabulary_size = 100\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default(), tf.device('/cpu:0'):\n",
    "  \n",
    "    # Input data.\n",
    "    idx = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "    print('idx', train_dataset.get_shape())\n",
    "\n",
    "    # Variable. A cada palabra del vocabulario le asigamos \"features\".\n",
    "    embeddings = tf.Variable(\n",
    "       tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "    print('embeddings', embeddings.get_shape())\n",
    "\n",
    "    # Look up embeddings for inputs.\n",
    "    embed = tf.nn.embedding_lookup(embeddings, idx)\n",
    "    # embed es un subset de embeddings cuyas filas son los idx\n",
    "    print('embed', embed.get_shape())\n",
    "    \n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    ts = np.random.randint(0, vocabulary_size, batch_size)\n",
    "    print(ts)\n",
    "    feed_dict = {train_dataset : ts}\n",
    "    res = session.run(embed, feed_dict = {train_dataset : ts})\n",
    "    # print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99289411  0.27742714 -0.98820704  0.15120512 -0.81263936 -0.96994382\n",
      "  0.94200498  0.90666956 -0.84608793 -0.99186325]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "K = 10\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.device('/cpu:0'):\n",
    "    lchild = tf.placeholder(tf.float32, shape=(K))\n",
    "    parent = tf.nn.tanh(tf.add(lchild, lchild))\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    inp = np.random.randn(K)\n",
    "    # print(session.run([parent], feed_dict={ lchild: inp }))\n",
    "    print( session.run(parent, feed_dict={ lchild: inp }) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
