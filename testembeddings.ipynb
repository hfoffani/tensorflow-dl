{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with Embeddings\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx (16,)\n",
      "embeddings (100, 8)\n",
      "embed (16, 8)\n",
      "[92 18 20 92  2 37 38 70 84 89 23 36 37 76 78 71]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "batch_size = 16\n",
    "embedding_size = 8\n",
    "vocabulary_size = 100\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "  \n",
    "    # Input data.\n",
    "    idx = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "    print('idx', idx.get_shape())\n",
    "\n",
    "    # Variable. A cada palabra del vocabulario le asignamos \"features\"\n",
    "    # que corresponden a un hiperplano.\n",
    "    embeddings = tf.Variable(\n",
    "       tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "    print('embeddings', embeddings.get_shape())\n",
    "\n",
    "    # Look up embeddings for inputs.\n",
    "    embed = tf.nn.embedding_lookup(embeddings, idx)\n",
    "    # embed es un subset de embeddings cuyas filas son los idx\n",
    "    print('embed', embed.get_shape())\n",
    "    \n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    ts = np.random.randint(0, vocabulary_size, batch_size)\n",
    "    print(ts)\n",
    "    res = session.run(embed, feed_dict = {idx : ts})\n",
    "    # print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.99798518  0.54673773  0.98603749 -0.78444868  0.59888685 -0.89904243\n",
      "  0.9991951   0.59237337  0.98600358  0.26037374]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "K = 10\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    lchild = tf.placeholder(tf.float32, shape=(K))\n",
    "    parent = tf.nn.tanh(tf.add(lchild, lchild))\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    inp = np.random.randn(K)\n",
    "    # print(session.run([parent], feed_dict={ lchild: inp }))\n",
    "    print( session.run(parent, feed_dict={ lchild: inp }) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
